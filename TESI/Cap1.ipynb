{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control-law design for full-state feedback\n",
    "\n",
    "The purpose of the control law is to allow us to assign as set of poles locations for the close-loop system that will correspond to satisfactory dynamic response in term of rise time and other measures of transient response. It's assumed for feedback purpose that all the elements of the state vector are at our disposal. In practice this assumption is ridiculous because it's known from design methods that rarely there are so many sensors. The assumption that all the state variables are available allows to proceed with this first step. When there will be introduced the reference in the system control, it will be used again in didactic purpose to shown the finality of tracking it, but the results will be almost identical by introducing noise inside the system to approach the reality. At the end of this chapter a Matlab example will expose a hand on lab to show how the control law influences the cart-inveted pendulum behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the control law\n",
    "\n",
    "How does it change the state equation when the system is inside a control loop? Below it's show the figure of a design block scheme:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|          | \n",
    "|:----------:|\n",
    "|![control law\\label{controllaw}](images/control-law.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-alignment=left;\"><a name=\"fig8\">Fig. 8</a> - Assumed system for control law design</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "u = -\\pmb{Kx} = \\begin{bmatrix}K_1 & K_2 & ... K_n \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x2 \\\\ . \\\\.\\\\.\\\\x_n\\end{bmatrix} \\label{eq:K} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation $\\eqref{eq:K}$ tell us that the system has a constant matrix in the state-vector feedback path gains, $K1,K2,....K_n$, and because there are n roots of the system, it's possible that there are enough degree of freedom to select arbitrarily and desired root location by choosing the proper value of $K_i$. Substituting the feedback law given in $\\eqref{eq:K}$ into the system described by $\\eqref{eq:stat-form}$ yields:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\dot{\\pmb{x}} = \\pmb{Fx - GKx} = (\\pmb{F - GK}) \\pmb x\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now writing:\n",
    "\\begin{equation}\n",
    "\\dot{\\pmb x}(t) = p_i e^{p_i t} \\pmb x_0 = (\\pmb{F-GK}) \\pmb x = (\\pmb{F-GK}) e^{p_i t} \\pmb x_0\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "\\pmb x(0) = \\pmb x_0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "(\\pmb{F-GK}) \\pmb x_0 = p_i \\pmb{x}_0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out an eigenvalues problem that it can be solved if and only if "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "det[s \\pmb I - (\\pmb{F-GK})] = 0 \\label{eq:dete} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluate, this yield an nth order polynomial in s containing the gains **K** so the roots of $\\eqref{eq:det}$ are in the *desirable* locations. We assume that desired locations are known, say,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}s=s_1,s_2,....,s_n\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the corresponding desired (control) characteristic equation is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\alpha_c(s) = (s-s_1)(s-s2)....(s-s_n) = 0 \\label{eq:alpha} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence the required elements of **K** are obtained by matching coefficients $\\eqref{eq:det}$ and $\\eqref{eq:alpha}$ ,forcing the systems's characteristic equation to be identical to the desired characteristic equation and the closed loop poles at the desired locations.\n",
    "\n",
    "Calculating the gains by using this technique becomes rather tedious when the order of the system is higher than 3. However there is an alternative to this method called **Ackerman's formula** divided in three steps process of converting to $(\\pmb F_c \\pmb G_c)$ solving for the gains, and converting back again into the very compact form:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\pmb K = [0,0,.....0,1]{\\mathcal{C}}^{-1} \\alpha_c({\\pmb F})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\mathcal C$ is the controllability matrix in $\\eqref{eq:C}$, n gives the order of the system and the dimension of the state variables and : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "\\alpha_c (\\pmb F) = \\pmb F^n + \\alpha_1 \\pmb F^{n-1} + ..... + \\alpha_n \\pmb I\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the $\\alpha_i$ are the coefficient corresponding to the desired poles locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example it's simulated a control-law with different pole placement to show how the cart pendulum change the overshoot and robustness. Please note that Matlab uses 'place' instead 'ackerman' function.\n",
    "```\n",
    "clear all, close all, clc\n",
    "\n",
    "m = 1;\n",
    "M = 5;\n",
    "L = 2;\n",
    "g = -10;\n",
    "d = 1;\n",
    "\n",
    "s = 1; % pendulum up (s=1)\n",
    "\n",
    "A = [0 1 0 0;\n",
    "    0 -d/M -m*g/M 0;\n",
    "    0 0 0 1;\n",
    "    0 -s*d/(M*L) -s*(m+M)*g/(M*L) 0];\n",
    "\n",
    "B = [0; 1/M; 0; s*1/(M*L)];\n",
    "eig(A)\n",
    "\n",
    "rank(ctrb(A,B))  % is it controllable\n",
    "\n",
    "%%  Pole placement\n",
    "% For more complex case a more reliable formula is available with \n",
    "% function place\n",
    "% p is a vector of desired eigenvalues\n",
    "p0 = [-.01; -.02; -.03; -.04]; % not enough\n",
    "p1 = [-.3; -.4; -.5; -.6];  % just barely\n",
    "p2 = [-1; -1.1; -1.2; -1.3]; % good\n",
    "p3 = [-2; -2.1; -2.2; -2.3]; % aggressive\n",
    "p4 = [-3; -3.1; -3.2; -3.3]; % aggressive\n",
    "%p = [-3.5; -3.6; -3.7; -3.8]; % breaks\n",
    "% create a list of vectors\n",
    "list_p = {p1,p2,p3,p4};\n",
    "% K = lqr(A,B,Q,R);\n",
    "\n",
    "% Plot a list of non-minimum phase zero \n",
    "for k = 1:numel(list_p)\n",
    "    tspan = 0:.001:30;\n",
    "    vec_p = list_p{k};\n",
    "    % Used place instead acker function\n",
    "    K = place(A,B,vec_p)\n",
    "    y0 = [-3; 0; pi+.1; 0];\n",
    "    [t,y] = ode45(@(t,y)cartpend(y,m,M,L,g,d,-K*(y-[1; 0; pi; 0])),tspan,y0);    \n",
    "    plot(t,y(:,1)); hold on;\n",
    "end\n",
    "```\n",
    "Print out the K values:\n",
    "```\n",
    "K =\n",
    "\n",
    "   -0.0360   -1.3420   71.9720   18.6840\n",
    "\n",
    "\n",
    "K =\n",
    "\n",
    "   -1.7160   -7.0260  142.5320   58.0520\n",
    "\n",
    "\n",
    "K =\n",
    "\n",
    "  -21.2520  -40.6460  379.6040  165.2920\n",
    "\n",
    "\n",
    "K =\n",
    "\n",
    "  -98.2080 -125.8660  851.5160  375.7320\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|          |\n",
    "|:----------:|\n",
    "|![modalblock\\label{modalblock}](images/poleplacement.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-alignment=left;\"><a name=\"fig9\">Fig. 9</a> - Some $K$ values based on different pole placement. The start position is x = -3 and $\\theta= \\pi +0.1$. Finale reference position is x = 1 $\\theta = \\pi$. It's worthwhile to note than more aggressively is equal to require more energy and less robustness </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be to note the system has to work harder to move pole long way (large gains) and reduce the control effort. In addition it's necessary to mention that the more aggressive will be the control the less robust the system will be because non linearity comes out respect the approximation done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to select pole locations for a good design\n",
    "As shown before, when selecting pole location it is always useful to keep in mind that control effort required is related to how far the open loop poles are moved by the feedback. Furthermore, when a zero is near a pole, the system may be nearly uncontrollable. The designer philosophy will take in account to fix only the undesirable aspects of the open loop response and avoids either large increases bandwidth or efforts to move poles that are near zeros will typically allow smaller gains, and thus smaller controls actuators.\n",
    "There are 2 main ways to overcome the problem. First deals dominant second order poles, second is Linear Quadratic Regulator; in this paper it will be show the second because more suited with state variables in feedback controls for higher dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear quadratic regulator\n",
    "\n",
    "We have seen in the previous sections that if $(F, G)$ is controllable, then it is possible to arbitrarily manipulate the eigenvalues of the closed-loop system $(\\pmb{A − BK})$ through choice of a full-state feedback control law $u = −\\pmb{Kx}$. This implicitly assumes that full-state measurements are available (i.e., $H = I$ and $J = 0$, so that $\\pmb y = \\pmb x$). Given a controllable system, and either measurements of the full-state or an observable system with a full-state estimate, there are many choices of stabilizing control laws $u = −\\pmb{Kx}$. It is possible to make the eigenvalues of the closed-loop system ($\\pmb A − \\pmb{BK})$ arbitrarily stable, placing them as far as desired in the left-half of the complex plane. However, overly stable eigenvalues may require exceedingly expensive control expenditure and might also result in actuation signals that exceed maximum allowable values. Choosing very stable eigenvalues may also cause the control system to over-react to noise and disturbances, much as a new driver will over-react to vibrations in the steering wheel, causing the closed-loop system to jitter. Over stabilization can counter-intuitively degrade robustness and may lead to instability if there are small time delays or unmodeled dynamics. Choosing the best gain matrix $\\pmb K$ to stabilize the system without expending too much control effort is an important goal in optimal control. A balance must be struck between the stability of the closed-loop system and the aggressiveness of control. It is important to take control expenditure into account:\n",
    " 1. to prevent the controller from over-reacting to high-frequency noise and disturbances\n",
    " 2. that actuation does not exceed maximum allowed amplitudes\n",
    " 3. that control is not prohibitively expensive. \n",
    "\n",
    "In particular, the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "J(t) = \\int\\limits_{0}^{t} {\\pmb x(\\tau)^* \\pmb Q x(\\tau) + \\pmb u(\\tau)^* \\pmb R u(\\tau) d\\tau}\n",
    "\\label{eq:costfunc} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "balances the cost of effective regulation of the state with the cost of control. The matrices **Q** and **R** weight the cost of deviations of the state from zero and the cost of actuation, respectively. The matrix **Q** is positive semi-definite, and **R** is positive definite; these matrices are often diagonal, and the diagonal elements may be tuned to change the relative importance of the control objectives.\n",
    "Adding such a cost function makes choosing the control law a well-posed optimization problem. The linear-quadratic-regulator (LQR) control law $u = −\\pmb K_r \\pmb x$ is designed to minimize $J = \\lim\\limits_{t \\to \\infty}{J(t)}$. LQR is so-named because it is a linear control law, designed for a linear system, minimizing a quadratic cost function, that regulates the state of the system to $J = \\lim\\limits_{t \\to \\infty}{\\pmb x(t) = \\pmb 0}$. Because the cost-function in $\\eqref{eq:costfunc}$ is quadratic, there is an analytical solution for the optimal controller gains $K_r$ , given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    \\pmb K_r = \\pmb R^{-1} \\pmb G^* \\pmb X\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\pmb X$ is the solution to an algebraic Riccati equation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "    \\pmb{F^*X + XF - XGR^{-1}G^*X + Q} = \\pmb 0\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving the above Riccati equation for $\\pmb X$, and hence for $\\pmb K_r$ , is numerically robust and already implemented in many programming languages. In Matlab, $K_r$ is obtained via :\n",
    "```\n",
    ">> Kr = lqr(F,G,Q,R);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As final hand-on lab it's shown a set of different choices of poles compared with the LQR gain; then it's calculated the cost-functions of any set of poles and compared like just before. Here the matlab code-snippet:\n",
    "\n",
    "```\n",
    "%% Compare with many examples of Pole Placement\n",
    "K = lqr(F,G,Q,R);\n",
    "u=@(x)-K*(x - wr);       % control law\n",
    "[t,x] = ode45(@(t,x)pendcart(x,m,M,L,g,d,u(x)),tspan,x0);\n",
    "xLQR = x;\n",
    "for k=1:length(t)\n",
    "    JLQR(k) = (x(k,:)-wr')*Q*(x(k,:)'-wr) + u(x(k,:)')^2*R;\n",
    "end\n",
    "\n",
    "CC = [0    0.4470    0.7410\n",
    "    0.8500    0.3250    0.0980\n",
    "    0.9290    0.6940    0.1250\n",
    "    0.4940    0.1840    0.5560\n",
    "    0.4660    0.6740    0.1880\n",
    "    0.3010    0.7450    0.9330\n",
    "    0.6350    0.0780    0.1840];\n",
    "\n",
    "CCgray = [0.2    0.6470    0.9410\n",
    "    0.9500    0.4250    0.1980\n",
    "    1    0.7940    0.2250\n",
    "    0.5940    0.2840    0.6560\n",
    "    0.4660    0.6740    0.1880\n",
    "    0.3010    0.7450    0.9330\n",
    "    0.6350    0.0780    0.1840];\n",
    "\n",
    "%try 100 different poles choises, plot graph of state-variables\n",
    "%and cost-functions together LQR gain.\n",
    "for count = 1:100\n",
    "    p = [-.5-3*rand; -.5-3*rand; -.5-3*rand; -.5-3*rand];\n",
    "\tK = place(F,G,p);\n",
    "    u=@(x)-K*(x - wr);       % control law\n",
    "    [t,x] = ode45(@(t,x)pendcart(x,m,M,L,g,d,u(x)),tspan,x0);\n",
    "    figure(1)\n",
    "    for j=1:4\n",
    "        plot(t(1:50:end),x(1:50:end,j),'Color',[.5 .5 .5] + .3*CC(j,:)), hold on;\n",
    "    end\n",
    "    for k=1:length(t)\n",
    "        J(k) = (x(k,:)-wr')*Q*(x(k,:)'-wr) + u(x(k,:)')^2*R;\n",
    "    end\n",
    "    figure(2)\n",
    "    Jz = cumtrapz(t,J);\n",
    "    plot(t(1:50:end),Jz(1:50:end),'Color',[.5 .5 .5]), hold on;\n",
    "end\n",
    "figure(1)\n",
    "    for j=1:4\n",
    "        plot(t(1:10:end),xLQR(1:10:end,j),'Color',CC(j,:),'LineWidth',2)\n",
    "        l1 = legend('x','v','\\theta','\\omega')\n",
    "    end\n",
    "figure(2)\n",
    "plot(t,cumtrapz(t,JLQR),'k','LineWidth',2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|           |\n",
    "|-----------|\n",
    "|![fig1.4](images/poleplacement2.png)|\n",
    "|![fig1.4.2](images/costfunctions.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"LQR\"> Fig. 10 </a>- Solution for Linear Quadratic Regulator compared with different set of poles locations; then the cost function is plotted in a visual way to show its functional value </p>"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
